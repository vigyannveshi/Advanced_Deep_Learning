{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Pyramids**\n",
    "* The content is followed using \"Feature Pyramid Network | Neck | Essentials of Object Detection\".<br>Reference: https://www.youtube.com/watch?v=FKsgO0U7CUw&list=PLivJwLo9VCUJXdO8SiOjZTWr_fXrAy4OQ&index=10\n",
    "* Extended by **Vigyannveshi** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from functools import partial\n",
    "\n",
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.ops.misc import Conv2dNormActivation\n",
    "\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_fm=tr.randn(size=(1,512,13,13))\n",
    "ml_fm=tr.randn(size=(1,256,26,26))\n",
    "ll_fm=tr.randn(size=(1,128,52,52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeakyRelu_Inplace=partial(\n",
    "    nn.LeakyReLU,\n",
    "    negative_slope=0.1,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "ConvBlockReduceChannels=partial(Conv2dNormActivation,\n",
    "                                kernel_size=1,\n",
    "                                activation_layer=LeakyRelu_Inplace\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_hl_reduce=ConvBlockReduceChannels(in_channels=512,out_channels=64)\n",
    "conv_ml_reduce=ConvBlockReduceChannels(in_channels=256,out_channels=64)\n",
    "conv_ll_reduce=ConvBlockReduceChannels(in_channels=128,out_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New HL shape - torch.Size([1, 64, 13, 13])\n",
      "New ML shape - torch.Size([1, 64, 26, 26])\n",
      "New LL shape - torch.Size([1, 64, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "hl_fm_r = conv_hl_reduce(hl_fm)\n",
    "ml_fm_r = conv_ml_reduce(ml_fm)\n",
    "ll_fm_r = conv_ll_reduce(ll_fm)\n",
    "\n",
    "print(f\"New HL shape - {hl_fm_r.shape}\")\n",
    "print(f\"New ML shape - {ml_fm_r.shape}\")\n",
    "print(f\"New LL shape - {ll_fm_r.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 26, 26])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_upsampler = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "hl_fm_r_upsampled = hl_upsampler(hl_fm_r)\n",
    "\n",
    "hl_fm_r_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 26, 26])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_ml_fused = tr.add(hl_fm_r_upsampled, ml_fm_r)\n",
    "\n",
    "hl_ml_fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "ConvSmoother = partial(\n",
    "                Conv2dNormActivation,\n",
    "                  in_channels=64, \n",
    "                  out_channels=64, \n",
    "                  kernel_size=3, \n",
    "                  activation_layer=LeakyRelu_Inplace\n",
    "               )\n",
    "\n",
    "hl_ml_fused_smoother = ConvSmoother()\n",
    "\n",
    "smooth_hl_ml_fused = hl_ml_fused_smoother(hl_ml_fused)\n",
    "\n",
    "print(smooth_hl_ml_fused.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeBackboneResult(NamedTuple):\n",
    "  hl_features: tr.Tensor\n",
    "  ml_features: tr.Tensor\n",
    "  ll_features: tr.Tensor\n",
    "\n",
    "class FakeBackbone(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x: tr.Tensor) -> FakeBackboneResult:\n",
    "    hl_fm = tr.randn(size=(1, 512, 13, 13))\n",
    "    ml_fm = tr.randn(size=(1, 256, 26, 26))\n",
    "    ll_fm = tr.randn(size=(1, 128, 52, 52))\n",
    "\n",
    "    return FakeBackboneResult(\n",
    "        hl_features=hl_fm,\n",
    "        ml_features=ml_fm,\n",
    "        ll_features=ll_fm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPNNeck(nn.Module):\n",
    "  def __init__(self, in_channels: list[int], out_channels: int):\n",
    "    super().__init__()\n",
    "\n",
    "    LeakyRelu_Inplace = partial(\n",
    "        nn.LeakyReLU,\n",
    "        negative_slope=0.1,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    ConvBlock = partial(Conv2dNormActivation, activation_layer=LeakyRelu_Inplace)\n",
    "\n",
    "    self.hl_channel_reducer = ConvBlock(\n",
    "        in_channels=in_channels[0],\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "    )\n",
    "\n",
    "    self.ml_channel_reducer = ConvBlock(\n",
    "        in_channels=in_channels[1],\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "    )\n",
    "\n",
    "    self.ll_channel_reducer = ConvBlock(\n",
    "        in_channels=in_channels[2],\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "    )\n",
    "\n",
    "    self.ml_smoother = ConvBlock(\n",
    "        in_channels=out_channels,\n",
    "        out_channels=out_channels,\n",
    "    )\n",
    "\n",
    "    self.ll_smoother = ConvBlock(\n",
    "        in_channels=out_channels,\n",
    "        out_channels=out_channels,\n",
    "    )\n",
    "\n",
    "  def forward(self, \n",
    "              hl_features:torch.Tensor, \n",
    "              ml_features:torch.Tensor,\n",
    "              ll_features:torch.Tensor):\n",
    "    \n",
    "    hl_channel_r = self.hl_channel_reducer(hl_features)\n",
    "    ml_channel_r = self.ml_channel_reducer(ml_features)\n",
    "    ll_channel_r = self.ll_channel_reducer(ll_features)\n",
    "\n",
    "    upsample_hl = F.interpolate(\n",
    "        hl_channel_r,\n",
    "        size=[ml_channel_r.size(2), ml_channel_r.size(3)],\n",
    "        mode=\"nearest\",\n",
    "    )\n",
    "\n",
    "    fused_hl_ml = upsample_hl + ml_channel_r\n",
    "    smoothed_ml_features = self.ml_smoother(fused_hl_ml)\n",
    "\n",
    "    upsample_ml = F.interpolate(\n",
    "        smoothed_ml_features,\n",
    "        size=[ll_channel_r.size(2), ll_channel_r.size(3)],\n",
    "        mode=\"nearest\",\n",
    "    )\n",
    "    fused_ml_ll = upsample_ml + ll_channel_r\n",
    "    smoothed_ll_features = self.ll_smoother(fused_ml_ll)\n",
    "\n",
    "    out = [hl_channel_r, smoothed_ml_features, smoothed_ll_features]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neck = FPNNeck(in_channels=[512, 256, 128], out_channels=64)\n",
    "backbone = FakeBackbone()\n",
    "\n",
    "backbone_output = backbone(tr.randn(size=(1, 3, 416, 416)))\n",
    "\n",
    "enriched_hl_features, enriched_ml_features, enriched_ll_features = neck(backbone_output.hl_features, \n",
    "     backbone_output.ml_features, \n",
    "     backbone_output.ll_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 13, 13])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_hl_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 26, 26])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_ml_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 52, 52])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_ll_features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
