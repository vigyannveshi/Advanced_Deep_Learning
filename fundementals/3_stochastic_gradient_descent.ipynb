{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stochastic Gradient Descent**\n",
    "\n",
    "Learnt it using:<br>\n",
    "**Reference: https://www.youtube.com/watch?v=V7KBAa_gh4c&list=PLKnIA16_RmvZvBbJex7T84XYRmor3IPK1&index=3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "X,y=load_diabetes(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n",
      "151.88331005254167\n"
     ]
    }
   ],
   "source": [
    "reg=LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399338661568968"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=reg.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating own class for multiple variable linear regression using gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "\n",
    "    def __init__(self,learning_rate=0.01, epochs=100):\n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.lr=learning_rate\n",
    "        self.epochs=epochs\n",
    "\n",
    "    def fit(self, X_train,y_train):\n",
    "        # initialize your coefs\n",
    "        self.intercept_=0\n",
    "        self.coef_=np.ones(shape=X_train.shape[1])\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            # update all the coefs and intercept\n",
    "            y_hat=self.intercept_+(X_train) @ (self.coef_)\n",
    "            intercept_der=-2*np.mean(y_train-y_hat)\n",
    "            # vectorization (we don't need to use a loop)\n",
    "            coef_der=(-2/X_train.shape[0])*((y_train-y_hat).T@(X_train))\n",
    "            # updating intercept\n",
    "            self.intercept_=self.intercept_-self.lr*intercept_der\n",
    "            # updating coefficients\n",
    "            self.coef_=self.coef_-self.lr*coef_der\n",
    "\n",
    "        print(self.intercept_,self.coef_)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self.intercept_+(X_test) @ (self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.52896930987225 [ 2.63772241  1.19060622  5.06046267  4.31375004  2.44715577  1.99246132\n",
      " -1.48838841  3.60218122  5.24193975  3.51394813]\n",
      "Time taken is 0.004676342010498047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.12800129775948377"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdr=GDRegressor(epochs=100,learning_rate=0.01)\n",
    "start=time.time()\n",
    "gdr.fit(X_train,y_train)\n",
    "print(f\"Time taken is {time.time()-start}\")\n",
    "y_pred=gdr.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating own class for multiple variable linear regression using stochastic gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Schedular\n",
    "t0,t1=5,50\n",
    "def learning_rate(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "\n",
    "class SGDRegressor:\n",
    "\n",
    "    def __init__(self,learning_rate=0.01, epochs=100):\n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.lr=learning_rate\n",
    "        self.epochs=epochs\n",
    "\n",
    "    def fit(self, X_train,y_train):\n",
    "        # initialize your coefs\n",
    "        self.intercept_=0\n",
    "        self.coef_=np.ones(shape=X_train.shape[1])\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                # making learning rate as a function of epochs\n",
    "                # self.lr=learning_rate(i*X.shape[0]+j) \n",
    "\n",
    "                idx=np.random.randint(0,X_train.shape[0]) # high not included\n",
    "                y_hat=(X_train[idx]@self.coef_)+self.intercept_ # a scalar\n",
    "                intercept_der=-2*(y_train[idx]-y_hat)\n",
    "                coef_der=-2*(y_train[idx]-y_hat)*X_train[idx]\n",
    "                self.intercept_=self.intercept_-(self.lr*intercept_der)\n",
    "                self.coef_=self.coef_-(self.lr*coef_der)\n",
    "\n",
    "        print(self.intercept_,self.coef_)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self.intercept_+(X_test) @ (self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.8492558195985 [  -5.82272059 -218.89075267  519.76642413  321.06284175  -92.20777525\n",
      " -124.55094901 -193.87848892   99.41504224  521.72339499   53.90100523]\n",
      "Time taken is 0.1647017002105713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4516543615990085"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=SGDRegressor(epochs=40,learning_rate=0.1)\n",
    "start=time.time()\n",
    "sgd.fit(X_train,y_train)\n",
    "print(f\"Time taken is {time.time()-start}\")\n",
    "y_pred=sgd.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is 0.0039441585540771484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42015019252181973"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg=SGDRegressor(max_iter=100,learning_rate='constant',eta0=0.01)\n",
    "start=time.time()\n",
    "reg.fit(X_train,y_train)\n",
    "print(f\"Time taken is {time.time()-start}\")\n",
    "y_pred=reg.predict(X_test)\n",
    "r2_score(y_test,y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
