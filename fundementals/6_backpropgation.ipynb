{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Backpropogation**\n",
    "\n",
    "* Was published in **\"Learning representations by back-propating errors\"** by **D. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams**\n",
    "    * **Reference: https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf**\n",
    "\n",
    "* The paper enabled the world to come out of AI winter!!! \n",
    "\n",
    "* Understanding it mathematically with expressions is available and taught by most of the courses. What they miss out on is the implementation of this algorithm in code.\n",
    "\n",
    "* The notebook will implement back propogation for two simple datasets to solve regression and classification problems\n",
    "\n",
    "* **Reference: https://www.youtube.com/watch?v=ma6hWrU-LaI**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solving Regression using Backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>resume_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  resume_score  lpa\n",
       "0     8             8    4\n",
       "1     7             9    5\n",
       "2     6            10    6\n",
       "3     5            12    7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','resume_score','lpa'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    '''\n",
    "        Layer_dims: neural network architecture, eg: [2,2,1]\n",
    "        It will create weights and biases (trainable params) and will provide random value\n",
    "        {temporarily w=0.1,b=0}\n",
    "    '''\n",
    "    np.random.seed(3)\n",
    "    parameters={}\n",
    "    L=len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters[f'W{l}']=np.ones((layer_dims[l-1],layer_dims[l]))*0.1\n",
    "        parameters[f'b{l}']=np.zeros((layer_dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev,W,b):\n",
    "    '''\n",
    "        Calculates output of any given neuron\n",
    "    '''\n",
    "    return W.T @ A_prev +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propogation\n",
    "\n",
    "def L_Layer_forward(X,parameters):\n",
    "    A=X\n",
    "    L=len(parameters)//2    # no of layers of a Neural Network\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "        A_prev=A\n",
    "        Wl=parameters[f\"W{l}\"]\n",
    "        bl=parameters[f\"b{l}\"]\n",
    "\n",
    "        # print(f\"A{l-1}: {A_prev}\")\n",
    "        # print(f\"W{l}: {Wl}\")\n",
    "        # print(f\"b{l}: {bl}\")\n",
    "        # print(\"--\"*20)\n",
    "\n",
    "        A=linear_forward(A_prev,Wl,bl)\n",
    "        # print(f\"A{l}: {A}\")\n",
    "        # print(\"**\"*20)\n",
    "    return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8]\n",
      " [8]]\n",
      "4\n",
      "{'W1': array([[0.1, 0.1],\n",
      "       [0.1, 0.1]]), 'b1': array([[0.],\n",
      "       [0.]]), 'W2': array([[0.1],\n",
      "       [0.1]]), 'b2': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "X=df[['cgpa','resume_score']].values[0].reshape(2,1) # shape(no of features, no of training example)\n",
    "y=df[['lpa']].values[0][0]\n",
    "\n",
    "# parameter initialization\n",
    "parameters=initialize_parameters([2,2,1])\n",
    "print(X)\n",
    "print(y)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32]]),\n",
       " array([[1.6],\n",
       "        [1.6]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_Layer_forward(X,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "    eta=0.001\n",
    "    parameters['W2'][0][0]=parameters['W2'][0][0]+(eta*2*(y-y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0]=parameters['W2'][1][0]+(eta*2*(y-y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0]=parameters['W2'][1][0]+(eta*2*(y-y_hat))\n",
    "\n",
    "    parameters['W1'][0][0]=parameters['W1'][0][0]+(eta*2*(y-y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "    parameters['W1'][0][1]=parameters['W1'][0][1]+(eta*2*(y-y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "    parameters['b1'][0][0]=parameters['b1'][0][0]+(eta*2*(y-y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0]=parameters['W1'][1][0]+(eta*2*(y-y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "    parameters['W1'][1][1]=parameters['W1'][1][1]+(eta*2*(y-y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "    parameters['b1'][1][0]=parameters['b1'][1][0]+(eta*2*(y-y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['cgpa','resume_score']].values[0].reshape(2,1) # shape(no of features, no of training example)\n",
    "y=df[['lpa']].values[0][0]\n",
    "\n",
    "# parameter initialization\n",
    "parameters=initialize_parameters([2,2,1])\n",
    "y_hat,A1=L_Layer_forward(X,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32000000000000006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=y_hat[0][0]\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6],\n",
       "       [1.6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776],\n",
       "        [0.111776]]),\n",
       " 'b2': array([[0.119136]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['cgpa','resume_score']].values[1].reshape(2,1) # shape(no of features, no of training example)\n",
    "y=df[['lpa']].values[0][0]\n",
    "\n",
    "y_hat,A1=L_Layer_forward(X,parameters)\n",
    "y_hat=y_hat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.11264256, 0.11437433],\n",
       "        [0.11264256, 0.11437433]]),\n",
       " 'b1': array([[0.00168856],\n",
       "        [0.00168856]]),\n",
       " 'W2': array([[0.12371702],\n",
       "        [0.12371702]]),\n",
       " 'b2': array([[0.13071593]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 25.321744156025517\n",
      "Epoch: 2. Loss: 18.320004165722047\n",
      "Epoch: 3. Loss: 9.473661050729628\n",
      "Epoch: 4. Loss: 3.2520938634031613\n",
      "Epoch: 5. Loss: 1.3407132589299962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744],\n",
       "        [0.48302736]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch implementation\n",
    "parameters=initialize_parameters([2,2,1])\n",
    "epochs=5\n",
    "\n",
    "for i in range(epochs):\n",
    "    Loss=[]\n",
    "\n",
    "    for j in range(df.shape[0]):\n",
    "        X=df[['cgpa','resume_score']].values[j].reshape(2,1) \n",
    "        y=df[['lpa']].values[j][0]\n",
    "\n",
    "        # forward propagation\n",
    "        y_hat,A1=L_Layer_forward(X,parameters)\n",
    "        y_hat=y_hat[0][0]\n",
    "\n",
    "        # backward propogation\n",
    "        update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "        Loss.append((y-y_hat)**2)\n",
    "    print(f\"Epoch: {i+1}. Loss: {np.array(Loss).mean()}\")\n",
    "\n",
    "parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 23:10:43.554870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 23:10:43.554968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 23:10:43.558036: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 23:10:43.569616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 23:10:44.581852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2,activation='linear',input_dim=2))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.83731353, -0.85734546],\n",
       "        [-1.014962  ,  0.06906283]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.5341526],\n",
       "        [-1.3330967]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights=[np.array([[0.1,  0.1],\n",
    "        [0.1,  0.1]], dtype=np.float32),\n",
    " np.array([0., 0.], dtype=np.float32),\n",
    " np.array([[0.1],\n",
    "        [0.1]], dtype=np.float32),\n",
    " np.array([0.], dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(new_weights)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 26.6234\n",
      "Epoch 2/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.9340\n",
      "Epoch 3/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 18.5055\n",
      "Epoch 4/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 13.7931\n",
      "Epoch 5/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 9.4742\n",
      "Epoch 6/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.0570\n",
      "Epoch 7/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4934\n",
      "Epoch 8/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5321\n",
      "Epoch 9/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9171\n",
      "Epoch 10/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3370\n",
      "Epoch 11/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6221\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4365\n",
      "Epoch 13/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3034\n",
      "Epoch 14/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1809\n",
      "Epoch 15/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1046\n",
      "Epoch 16/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0105\n",
      "Epoch 17/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0316\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9941\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9435\n",
      "Epoch 20/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9245\n",
      "Epoch 21/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9070\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8852\n",
      "Epoch 23/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8727\n",
      "Epoch 24/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8422\n",
      "Epoch 25/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8604\n",
      "Epoch 26/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8387\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7929\n",
      "Epoch 28/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8256\n",
      "Epoch 29/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7711\n",
      "Epoch 30/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7600\n",
      "Epoch 31/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7210\n",
      "Epoch 32/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7387\n",
      "Epoch 33/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7089\n",
      "Epoch 34/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7239\n",
      "Epoch 35/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6808\n",
      "Epoch 36/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6605\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6481\n",
      "Epoch 38/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6533\n",
      "Epoch 39/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6699\n",
      "Epoch 40/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6374\n",
      "Epoch 41/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6365\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5950\n",
      "Epoch 43/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5736\n",
      "Epoch 44/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5621\n",
      "Epoch 45/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5301\n",
      "Epoch 46/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5217\n",
      "Epoch 47/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5184\n",
      "Epoch 48/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5023\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4747\n",
      "Epoch 50/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4681\n",
      "Epoch 51/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4663\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4464\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4337\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4386\n",
      "Epoch 55/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4140\n",
      "Epoch 56/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3972\n",
      "Epoch 57/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3912\n",
      "Epoch 58/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3785\n",
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "Epoch 60/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3615\n",
      "Epoch 61/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3438\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3424\n",
      "Epoch 63/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3380\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3134\n",
      "Epoch 65/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3035\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2996\n",
      "Epoch 67/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3049\n",
      "Epoch 68/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2840\n",
      "Epoch 69/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2510\n",
      "Epoch 73/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2327\n",
      "Epoch 74/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2264\n",
      "Epoch 75/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7dc04f79a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:-1].values,df['lpa'].values,epochs=75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.03950404, 0.03950404],\n",
       "        [0.5673128 , 0.5673128 ]], dtype=float32),\n",
       " array([0.23207285, 0.23207285], dtype=float32),\n",
       " array([[0.43774492],\n",
       "        [0.43774492]], dtype=float32),\n",
       " array([0.24062337], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solving Classification problem using Backpropogation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>resume_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  resume_score  placed\n",
       "0     8             8       1\n",
       "1     7             9       1\n",
       "2     6            10       0\n",
       "3     5             5       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]],columns=['cgpa','resume_score','placed'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    '''\n",
    "        Layer_dims: neural network architecture, eg: [2,2,1]\n",
    "        It will create weights and biases (trainable params) and will provide random value\n",
    "        {temporarily w=0.1,b=0}\n",
    "    '''\n",
    "    np.random.seed(3)\n",
    "    parameters={}\n",
    "    L=len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters[f'W{l}']=np.ones((layer_dims[l-1],layer_dims[l]))*0.1\n",
    "        parameters[f'b{l}']=np.zeros((layer_dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev,W,b):\n",
    "    '''\n",
    "        Calculates output of any given neuron\n",
    "    '''\n",
    "    return sigmoid(W.T @ A_prev +b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propogation\n",
    "\n",
    "def L_Layer_forward(X,parameters):\n",
    "    A=X\n",
    "    L=len(parameters)//2    # no of layers of a Neural Network\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "        A_prev=A\n",
    "        Wl=parameters[f\"W{l}\"]\n",
    "        bl=parameters[f\"b{l}\"]\n",
    "\n",
    "        # print(f\"A{l-1}: {A_prev}\")\n",
    "        # print(f\"W{l}: {Wl}\")\n",
    "        # print(f\"b{l}: {bl}\")\n",
    "        # print(\"--\"*20)\n",
    "\n",
    "        A=linear_forward(A_prev,Wl,bl)\n",
    "        # print(f\"A{l}: {A}\")\n",
    "        # print(\"**\"*20)\n",
    "    return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "    eta=0.001\n",
    "    parameters['W2'][0][0]=parameters['W2'][0][0]+(eta*(y-y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0]=parameters['W2'][1][0]+(eta*(y-y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0]=parameters['W2'][1][0]+(eta*(y-y_hat))\n",
    "\n",
    "    parameters['W1'][0][0]=parameters['W1'][0][0]+(eta*(y-y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
    "    parameters['W1'][0][1]=parameters['W1'][0][1]+(eta*(y-y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
    "    parameters['b1'][0][0]=parameters['b1'][0][0]+(eta*(y-y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
    "\n",
    "    parameters['W1'][1][0]=parameters['W1'][1][0]+(eta*(y-y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
    "    parameters['W1'][1][1]=parameters['W1'][1][1]+(eta*(y-y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
    "    parameters['b1'][1][0]=parameters['b1'][1][0]+(eta*(y-y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 0.71050114771481\n",
      "Epoch: 2. Loss: 0.6993819908638181\n",
      "Epoch: 3. Loss: 0.6993584295593506\n",
      "Epoch: 4. Loss: 0.6993349670157292\n",
      "Epoch: 5. Loss: 0.6993116027845855\n",
      "Epoch: 6. Loss: 0.6992883364197799\n",
      "Epoch: 7. Loss: 0.6992651674773883\n",
      "Epoch: 8. Loss: 0.6992420955156897\n",
      "Epoch: 9. Loss: 0.6992191200951554\n",
      "Epoch: 10. Loss: 0.6991962407784353\n",
      "Epoch: 11. Loss: 0.699173457130348\n",
      "Epoch: 12. Loss: 0.6991507687178667\n",
      "Epoch: 13. Loss: 0.6991281751101095\n",
      "Epoch: 14. Loss: 0.6991056758783265\n",
      "Epoch: 15. Loss: 0.6990832705958882\n",
      "Epoch: 16. Loss: 0.699060958838274\n",
      "Epoch: 17. Loss: 0.6990387401830616\n",
      "Epoch: 18. Loss: 0.699016614209914\n",
      "Epoch: 19. Loss: 0.6989945805005696\n",
      "Epoch: 20. Loss: 0.6989726386388295\n",
      "Epoch: 21. Loss: 0.698950788210548\n",
      "Epoch: 22. Loss: 0.6989290288036194\n",
      "Epoch: 23. Loss: 0.6989073600079687\n",
      "Epoch: 24. Loss: 0.6988857814155395\n",
      "Epoch: 25. Loss: 0.6988642926202835\n",
      "Epoch: 26. Loss: 0.6988428932181494\n",
      "Epoch: 27. Loss: 0.6988215828070719\n",
      "Epoch: 28. Loss: 0.6988003609869615\n",
      "Epoch: 29. Loss: 0.6987792273596933\n",
      "Epoch: 30. Loss: 0.6987581815290967\n",
      "Epoch: 31. Loss: 0.6987372231009441\n",
      "Epoch: 32. Loss: 0.6987163516829413\n",
      "Epoch: 33. Loss: 0.6986955668847165\n",
      "Epoch: 34. Loss: 0.6986748683178102\n",
      "Epoch: 35. Loss: 0.6986542555956645\n",
      "Epoch: 36. Loss: 0.6986337283336133\n",
      "Epoch: 37. Loss: 0.6986132861488713\n",
      "Epoch: 38. Loss: 0.6985929286605251\n",
      "Epoch: 39. Loss: 0.698572655489522\n",
      "Epoch: 40. Loss: 0.6985524662586604\n",
      "Epoch: 41. Loss: 0.6985323605925797\n",
      "Epoch: 42. Loss: 0.6985123381177509\n",
      "Epoch: 43. Loss: 0.6984923984624657\n",
      "Epoch: 44. Loss: 0.6984725412568277\n",
      "Epoch: 45. Loss: 0.6984527661327423\n",
      "Epoch: 46. Loss: 0.6984330727239069\n",
      "Epoch: 47. Loss: 0.6984134606658015\n",
      "Epoch: 48. Loss: 0.6983939295956789\n",
      "Epoch: 49. Loss: 0.6983744791525557\n",
      "Epoch: 50. Loss: 0.6983551089772018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09950872, 0.09857616],\n",
       "        [0.09951369, 0.09857676]]),\n",
       " 'b1': array([[-0.00031786],\n",
       "        [-0.00031795]]),\n",
       " 'W2': array([[0.09240871],\n",
       "        [0.0924183 ]]),\n",
       " 'b2': array([[0.09186164]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch implementation\n",
    "parameters=initialize_parameters([2,2,1])\n",
    "epochs=50\n",
    "\n",
    "for i in range(epochs):\n",
    "    Loss=[]\n",
    "\n",
    "    for j in range(df.shape[0]):\n",
    "        X=df[['cgpa','resume_score']].values[j].reshape(2,1) \n",
    "        y=df[['placed']].values[j][0]\n",
    "\n",
    "        # forward propagation\n",
    "        y_hat,A1=L_Layer_forward(X,parameters)\n",
    "        y_hat=y_hat[0][0]\n",
    "\n",
    "        # backward propogation\n",
    "        update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "        Loss.append(-y*np.log(y_hat)-(1-y)*np.log(1-y_hat))\n",
    "    print(f\"Epoch: {i+1}. Loss: {np.array(Loss).mean()}\")\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2,activation='sigmoid',input_dim=2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.0494909 , -0.39669693],\n",
       "        [ 0.16728997,  0.66143227]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.4054867],\n",
       "        [0.3735199]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights=[np.array([[0.1,  0.1],\n",
    "        [0.1,  0.1]], dtype=np.float32),\n",
    " np.array([0., 0.], dtype=np.float32),\n",
    " np.array([[0.1],\n",
    "        [0.1]], dtype=np.float32),\n",
    " np.array([0.], dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(new_weights)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.01) \n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7055\n",
      "Epoch 2/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6942\n",
      "Epoch 3/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6935\n",
      "Epoch 4/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6947\n",
      "Epoch 5/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6931\n",
      "Epoch 6/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6931\n",
      "Epoch 7/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6928\n",
      "Epoch 8/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6928\n",
      "Epoch 9/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6928\n",
      "Epoch 10/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6938\n",
      "Epoch 11/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6931\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6925\n",
      "Epoch 13/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6924\n",
      "Epoch 14/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6946\n",
      "Epoch 15/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6937\n",
      "Epoch 16/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6922\n",
      "Epoch 17/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6927\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6925\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6936\n",
      "Epoch 20/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6940\n",
      "Epoch 21/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6923\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6934\n",
      "Epoch 23/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6941\n",
      "Epoch 24/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6934\n",
      "Epoch 25/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6924\n",
      "Epoch 26/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6932\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6921\n",
      "Epoch 28/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6930\n",
      "Epoch 29/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6923\n",
      "Epoch 30/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6930\n",
      "Epoch 31/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6939\n",
      "Epoch 32/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6919\n",
      "Epoch 33/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6930\n",
      "Epoch 34/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6936\n",
      "Epoch 35/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6929\n",
      "Epoch 36/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6919\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6931\n",
      "Epoch 38/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6927\n",
      "Epoch 39/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6920\n",
      "Epoch 40/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6926\n",
      "Epoch 41/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6923\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6915\n",
      "Epoch 43/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6915\n",
      "Epoch 44/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6923\n",
      "Epoch 45/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6933\n",
      "Epoch 46/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6913\n",
      "Epoch 47/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6923\n",
      "Epoch 48/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6909\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6912\n",
      "Epoch 50/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6911\n",
      "Epoch 51/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6911\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6908\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6910\n",
      "Epoch 55/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6918\n",
      "Epoch 56/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6904\n",
      "Epoch 57/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908\n",
      "Epoch 58/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908\n",
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6907\n",
      "Epoch 60/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6916\n",
      "Epoch 61/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6913\n",
      "Epoch 63/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6907\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6904\n",
      "Epoch 65/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6903\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6901\n",
      "Epoch 67/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6900\n",
      "Epoch 68/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6910\n",
      "Epoch 69/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6899\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6898\n",
      "Epoch 73/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904\n",
      "Epoch 74/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6918\n",
      "Epoch 75/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7dc01c8040>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:-1].values,df['placed'].values,epochs=75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.2344019 ,  0.2344019 ],\n",
       "        [-0.03048659, -0.03048659]], dtype=float32),\n",
       " array([-0.36952424, -0.36952424], dtype=float32),\n",
       " array([[0.11297886],\n",
       "        [0.11297886]], dtype=float32),\n",
       " array([-0.10295635], dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
